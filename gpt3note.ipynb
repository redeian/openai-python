{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 rows in the data.\n",
      "('it', 'อัพเกรด-ปากกายี้ห้อ?') : [-0.027002012357115746, 0.00606458680704236, 0.024204017594456673, -0.03425506874918938, -0.008258161135017872]... (1536 entries)\n",
      "[(0.7411812717714277, ('it', 'อยู่ต่างจังหวัดมีส่งเครื่องให้ไหม/การเตรียมตัวรับเครื่อง?')), (0.7047203860382953, ('student_activity', 'สามารถติดตามข้อมูล ข่าวสาร สหกิจศึกษา ม.หอการค้าไทย ได้ที่ไหน')), (0.7015678454843883, ('student_activity', 'มีชมรมกีฬาอะไรบ้าง')), (0.7009822683697996, ('student_activity', 'ทุนกีฬาเปิดรับสมัครช่วงไหน')), (0.7007752094786921, ('student_activity', 'ช่วงไหนมีกิจกรรมกีฬาอะไรบ้าง และช่วงไหน'))]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# We have hosted the processed dataset, so you can download it directly without having to recreate it.\n",
    "# This dataset has already been split into sections, one row for each section of the Wikipedia page.\n",
    "\n",
    "df = pd.read_csv('./data/my_sections_text2.csv')\n",
    "df = df.set_index([\"title\", \"heading\"])\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "\n",
    "\n",
    "def get_embedding(text: str, model: str = EMBEDDING_MODEL):\n",
    "    result = openai.Embedding.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "\n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "\n",
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "\n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c)\n",
    "                  for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "        (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }\n",
    "\n",
    "\n",
    "# document_embeddings = load_embeddings(\"./data/olympics_sections_document_embeddings.csv\")\n",
    "\n",
    "# ===== OR, uncomment the below line to recaculate the embeddings from scratch. ========\n",
    "\n",
    "document_embeddings = compute_doc_embeddings(df)\n",
    "\n",
    "\n",
    "# An example embedding:\n",
    "example_entry = list(document_embeddings.items())[0]\n",
    "print(\n",
    "    f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")\n",
    "\n",
    "\n",
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "\n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "\n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "\n",
    "    return document_similarities\n",
    "\n",
    "\n",
    "x = order_document_sections_by_query_similarity(\n",
    "    \"Who won the men's high jump?\", document_embeddings)[:5]\n",
    "\n",
    "print(x)\n",
    "\n",
    "\n",
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\"\n",
    "\n",
    "\n",
    "\n",
    "# prompt = construct_prompt(\n",
    "#     \"Who won the 2020 Summer Olympics men's high jump?\",\n",
    "#     document_embeddings,\n",
    "#     df\n",
    "# )\n",
    "\n",
    "# print(\"===\\n\", prompt)\n",
    "\n",
    "\n",
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}\n",
    "\n",
    "\n",
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array],\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "\n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        **COMPLETIONS_API_PARAMS\n",
    "    )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(\n",
    "        question, context_embeddings)\n",
    "\n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "\n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.\n",
    "        document_section = df.loc[section_index]\n",
    "\n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "\n",
    "        chosen_sections.append(\n",
    "            SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "\n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "\n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\" You must answer in very short and concise way. \\n\\nContext:\\n\"\"\"\n",
    "\n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 4 document sections:\n",
      "('it', 'ต้องการใช้ VPN')\n",
      "('it', 'เข้าใช้งาน wifi ไม่ได้')\n",
      "('ipad', 'อัพเกรด อัพสเปค ไอแพดได้ไหม')\n",
      "('it', 'อัพเกรด-ปากกายี้ห้อ?')\n",
      "คุณสามารถติดตั้ง wifi ได้ด้วยขั้นตอนที่กล่าวไว้ โดยเลือกใช้งาน UTCC-Mobile และกรอก Username และ Password ที่ได้รับจากมหาวิทยาลัย\n"
     ]
    }
   ],
   "source": [
    "b = answer_query_with_context(\n",
    "    \"อยากติดตั้ง wifi อ่ะ\", df, document_embeddings)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 4 document sections:\n",
      "('it', 'เปลี่ยนรหัสแล้วเข้า mail ไม่ได้')\n",
      "('it', 'Sign in ด้วย UTCC Email เข้า Webex Meetingไม่ได้\\n\\xa0\\xa0กรณีที่ 1 ที่ยังไม่เคยลงทะเบียนสมัครเป็นสมาชิก\\xa0\\n\\xa0\\xa0กรณีที่ 2 ลืมรหัสผ่าน')\n",
      "('it', 'ไม่สามารถ Login เข้าใช้งาน MS Teams')\n",
      "('registrar', 'โปรโมชั่นสมัครเรียน')\n",
      "ติดต่อสำนักบริการคอมพิวเตอร์\n"
     ]
    }
   ],
   "source": [
    "b = answer_query_with_context(\n",
    "    \"password หาย\", df, document_embeddings)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('document_embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump(document_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled document_embeddings dictionary\n",
    "with open('document_embeddings.pickle', 'rb') as f:\n",
    "    document_embeddings_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaipy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26bdb124687998fbe26b32e2b22c487df6f5d7c2052478f4c5b084c9abc914a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
